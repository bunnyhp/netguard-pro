{"fsPath":"\\home\\jarvis\\NetGuard\\scripts\\ai_5min_aggregator.py","fileUuid":"744d8f7a-5c5a-45cc-b9df-0194a59ed79e","fileSizeBytes":36603,"numLines":890,"diffChanges":[{"originalStartLineNumberOneIndexed":582,"originalEndLineNumberExclusiveOneIndexed":585,"modifiedStartLineNumberOneIndexed":582,"modifiedEndLineNumberExclusiveOneIndexed":593,"addedLines":["def call_groq_api(prompt, api_key, config=None):","    \"\"\"Call Groq API with multiple model fallbacks\"\"\"","    if not config:","        # Default model list if no config provided","        models = [\"llama-3.3-70b-versatile\", \"llama-3.1-70b-versatile\"]","    else:","        models = config.get('ai_models', {}).get('groq_models', [\"llama-3.3-70b-versatile\"])","    ","    for model in models:","        try:","            logging.info(f\"Trying Groq model: {model}\")"],"tokenizedAddedLines":[1000567,1000568,1000569,1000570,1000571,1000572,1000573,300,1000574,236,1000575]},{"originalStartLineNumberOneIndexed":592,"originalEndLineNumberExclusiveOneIndexed":593,"modifiedStartLineNumberOneIndexed":600,"modifiedEndLineNumberExclusiveOneIndexed":601,"addedLines":["                \"model\": model,"],"tokenizedAddedLines":[1000576]},{"originalStartLineNumberOneIndexed":608,"originalEndLineNumberExclusiveOneIndexed":608,"modifiedStartLineNumberOneIndexed":616,"modifiedEndLineNumberExclusiveOneIndexed":618,"addedLines":["                ","                logging.info(f\"✅ Successfully used Groq model: {model}\")"],"tokenizedAddedLines":[73,1000577]},{"originalStartLineNumberOneIndexed":610,"originalEndLineNumberExclusiveOneIndexed":611,"modifiedStartLineNumberOneIndexed":620,"modifiedEndLineNumberExclusiveOneIndexed":628,"addedLines":["                logging.warning(f\"Groq model {model} failed: {response.status_code} - {response.text}\")","                continue","                ","        except Exception as e:","            logging.warning(f\"Error with Groq model {model}: {e}\")","            continue","    ","    logging.error(\"All Groq models failed\")"],"tokenizedAddedLines":[1000578,528,73,260,1000579,1000580,300,1000581]},{"originalStartLineNumberOneIndexed":612,"originalEndLineNumberExclusiveOneIndexed":612,"modifiedStartLineNumberOneIndexed":629,"modifiedEndLineNumberExclusiveOneIndexed":672,"addedLines":["","def call_openrouter_api(prompt, api_key, config=None):","    \"\"\"Call OpenRouter API with multiple model fallbacks\"\"\"","    if not config:","        # Default model list if no config provided","        models = [\"deepseek/deepseek-r1-distill-qwen-1.5b\", \"qwen/qwen-coder-480b\"]","    else:","        models = config.get('ai_models', {}).get('openrouter_models', [\"deepseek/deepseek-r1-distill-qwen-1.5b\"])","    ","    for model in models:","        try:","            logging.info(f\"Trying OpenRouter model: {model}\")","            url = \"https://openrouter.ai/api/v1/chat/completions\"","            headers = {","                'Authorization': f'Bearer {api_key}',","                'Content-Type': 'application/json',","                'HTTP-Referer': 'https://netguard-pro.local',","                'X-Title': 'NetGuard Pro AI Analysis'","            }","            ","            payload = {","                \"model\": model,","                \"messages\": [{\"role\": \"user\", \"content\": prompt}],","                \"temperature\": 0.3,","                \"max_tokens\": 4096","            }","            ","            response = requests.post(url, headers=headers, json=payload, timeout=60)","            ","            if response.status_code == 200:","                result = response.json()","                text = result['choices'][0]['message']['content']","                # Extract JSON from markdown code blocks if present","                if '```json' in text:","                    text = text.split('```json')[1].split('```')[0].strip()","                elif '```' in text:","                    text = text.split('```')[1].split('```')[0].strip()","                ","                logging.info(f\"✅ Successfully used OpenRouter model: {model}\")","                return json.loads(text)","            else:","                logging.warning(f\"OpenRouter model {model} failed: {response.status_code} - {response.text}\")","                continue"],"tokenizedAddedLines":[6,1000582,1000583,1000569,1000570,1000584,1000572,1000585,300,1000574,236,1000586,1000587,1000588,1000589,1000590,1000591,1000592,87,67,1000593,1000576,1000594,445,1000595,87,67,1000596,67,1000597,1000598,1000599,1000600,1000601,1000602,1000603,1000604,73,1000605,1000606,557,1000607,528]},{"originalStartLineNumberOneIndexed":614,"originalEndLineNumberExclusiveOneIndexed":615,"modifiedStartLineNumberOneIndexed":674,"modifiedEndLineNumberExclusiveOneIndexed":678,"addedLines":["            logging.warning(f\"Error with OpenRouter model {model}: {e}\")","            continue","    ","    logging.error(\"All OpenRouter models failed\")"],"tokenizedAddedLines":[1000608,1000580,300,1000609]},{"originalStartLineNumberOneIndexed":617,"originalEndLineNumberExclusiveOneIndexed":621,"modifiedStartLineNumberOneIndexed":680,"modifiedEndLineNumberExclusiveOneIndexed":692,"addedLines":["def call_gemini_api(prompt, api_key, config=None):","    \"\"\"Call Google Gemini API with multiple model fallbacks\"\"\"","    if not config:","        # Default model list if no config provided","        models = [\"gemini-2.5-pro\", \"gemini-2.5-flash\", \"gemini-2.0-flash\"]","    else:","        models = config.get('ai_models', {}).get('gemini_models', [\"gemini-2.5-pro\", \"gemini-2.5-flash\"])","    ","    for model in models:","        try:","            logging.info(f\"Trying Gemini model: {model}\")","            url = f\"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}\""],"tokenizedAddedLines":[1000610,1000611,1000569,1000570,1000612,1000572,1000613,300,1000574,236,1000614,1000615]},{"originalStartLineNumberOneIndexed":650,"originalEndLineNumberExclusiveOneIndexed":650,"modifiedStartLineNumberOneIndexed":721,"modifiedEndLineNumberExclusiveOneIndexed":723,"addedLines":["                ","                logging.info(f\"✅ Successfully used Gemini model: {model}\")"],"tokenizedAddedLines":[73,1000616]},{"originalStartLineNumberOneIndexed":652,"originalEndLineNumberExclusiveOneIndexed":654,"modifiedStartLineNumberOneIndexed":725,"modifiedEndLineNumberExclusiveOneIndexed":727,"addedLines":["                logging.warning(f\"Gemini model {model} failed: {response.status_code} - {response.text}\")","                continue"],"tokenizedAddedLines":[1000617,528]},{"originalStartLineNumberOneIndexed":656,"originalEndLineNumberExclusiveOneIndexed":657,"modifiedStartLineNumberOneIndexed":729,"modifiedEndLineNumberExclusiveOneIndexed":733,"addedLines":["            logging.warning(f\"Error with Gemini model {model}: {e}\")","            continue","    ","    logging.error(\"All Gemini models failed\")"],"tokenizedAddedLines":[1000618,1000580,300,1000619]},{"originalStartLineNumberOneIndexed":728,"originalEndLineNumberExclusiveOneIndexed":728,"modifiedStartLineNumberOneIndexed":804,"modifiedEndLineNumberExclusiveOneIndexed":805,"addedLines":["    openrouter_key = config.get('api_keys', {}).get('openrouter_api_key')"],"tokenizedAddedLines":[1000620]},{"originalStartLineNumberOneIndexed":729,"originalEndLineNumberExclusiveOneIndexed":730,"modifiedStartLineNumberOneIndexed":806,"modifiedEndLineNumberExclusiveOneIndexed":807,"addedLines":["    if not gemini_key and not groq_key and not openrouter_key:"],"tokenizedAddedLines":[1000621]},{"originalStartLineNumberOneIndexed":764,"originalEndLineNumberExclusiveOneIndexed":765,"modifiedStartLineNumberOneIndexed":841,"modifiedEndLineNumberExclusiveOneIndexed":842,"addedLines":["            # 3. Call AI API with complete fallback chain: Gemini → Groq → OpenRouter"],"tokenizedAddedLines":[1000622]},{"originalStartLineNumberOneIndexed":767,"originalEndLineNumberExclusiveOneIndexed":767,"modifiedStartLineNumberOneIndexed":844,"modifiedEndLineNumberExclusiveOneIndexed":845,"addedLines":["            # Try Gemini first (with multiple models)"],"tokenizedAddedLines":[1000623]},{"originalStartLineNumberOneIndexed":768,"originalEndLineNumberExclusiveOneIndexed":770,"modifiedStartLineNumberOneIndexed":846,"modifiedEndLineNumberExclusiveOneIndexed":848,"addedLines":["                logging.info(\"Step 3: Trying Gemini AI models...\")","                analysis = call_gemini_api(prompt, gemini_key, config)"],"tokenizedAddedLines":[1000624,1000625]},{"originalStartLineNumberOneIndexed":771,"originalEndLineNumberExclusiveOneIndexed":771,"modifiedStartLineNumberOneIndexed":849,"modifiedEndLineNumberExclusiveOneIndexed":850,"addedLines":["            # If Gemini fails, try Groq (with multiple models)"],"tokenizedAddedLines":[1000626]},{"originalStartLineNumberOneIndexed":772,"originalEndLineNumberExclusiveOneIndexed":777,"modifiedStartLineNumberOneIndexed":851,"modifiedEndLineNumberExclusiveOneIndexed":858,"addedLines":["                logging.warning(\"Gemini failed, trying Groq AI models...\")","                analysis = call_groq_api(prompt, groq_key, config)","            ","            # If Groq fails, try OpenRouter (with multiple models)","            if not analysis and openrouter_key:","                logging.warning(\"Groq failed, trying OpenRouter AI models...\")","                analysis = call_openrouter_api(prompt, openrouter_key, config)"],"tokenizedAddedLines":[1000627,1000628,67,1000629,1000630,1000631,1000632]}],"gitInfo":{"noRepoFound":true},"kind":"KIND_MODIFIED"}